# Zack Christiansen
# Data Analyst
## Masters Degree in Mathematics
_Dedicated to Constant Improvement_

### [View my LinkedIn Profile](https://www.linkedin.com/in/zack-christiansen-922705196/)

### Innovative and scientifically rigorous graduate with a diverse set of skills ranging from Data Visualization to Data Structures to Machine Learning. 

Detail-oriented Data Analyst transitioning into Data Engineering, with a strong foundation in data analysis, SQL, and Python, and hands-on experience building and optimizing data pipelines. Adept at transforming business requirements into scalable data solutions and leveraging analytical skills to ensure data integrity and usability. Experienced in working with relational databases, ETL processes, and cloud-based tools (e.g., AWS, GCP). Passionate about automating data workflows, improving data infrastructure, and enabling data-driven decision-making across teams. Currently expanding expertise in distributed systems, data warehousing, and tools like Spark, Airflow, and dbt to support large-scale data operations.
# Projects

---

# [Dissimilarities of Movie Descriptions(Python)](https://github.com/zacharychristian/Dissimilarities-of-Movie-Descriptions/blob/main/Cosine%20Similarity%20and%20Clustering.ipynb)
<img src="images/hierarchicalcluster.jpg?raw=true"/>

# [Apache Spark Polish Procurement Data Pipeline](https://github.com/zacharychristian/Apache-Spark-Polish-Procurement/tree/main).
<img src = "images/system_architecture.png?raw=true"/>


---

## Skills:

### Data Visualization
- Communicating data stories
- Visualization through graphs
- Simplifying complex ideas into interpretable pieces and combining to construct a narrative.

### SQL:
- Advanced Querying: Complex joins, window functions, CTEs, subqueries, pivot/unpivot, and aggregation techniques for in-depth data analysis and transformation.

- Performance Optimization: Proficient in query tuning, indexing strategies, execution plans, and optimizing large-scale data queries.

- Data Modeling: Experience designing normalized and denormalized schemas (star/snowflake), creating ER diagrams, and understanding relational data structures.

- ETL Development: Writing and maintaining SQL-based ETL/ELT processes for transforming and loading data into warehouses (e.g., Snowflake, BigQuery, Redshift).

- SQL in Analytics & Engineering: Used SQL for both analytical dashboards and backend pipeline logic—bridging data insights with engineering best practices.

- Version Control & CI/CD: Experience managing SQL scripts with Git and integrating into CI/CD pipelines for automated deployments.

### Python:
- Python for Data Engineering: Proficient in writing clean, modular, and scalable Python code for data extraction, transformation, and loading (ETL/ELT), automation scripts, and API integrations.

- PySpark: Experience with distributed data processing using PySpark for large-scale data transformations, performance tuning, and working with DataFrames and RDDs in a production context.

- Apache Airflow: Designed and scheduled DAGs for orchestrating complex ETL pipelines; comfortable with task dependencies, retries, and custom operators.

- Docker: Containerized Python applications and workflows for reproducibility and deployment across environments. Familiar with Dockerfiles, multi-stage builds, and container networking.

- Kubernetes (K8s): Understanding of container orchestration, managing Docker containers using Kubernetes for scalable and resilient data workflows.

- Data Pipelines & Workflow Automation: Built batch and streaming pipelines using Python with tools like Airflow, Spark, and custom schedulers.

- Testing & Code Quality: Experience with unit testing (pytest), logging, and monitoring for data pipelines to ensure robustness and observability.

Libraries & Tools:

- Core Libraries: pandas, NumPy, SQLAlchemy, requests, datetime, os, pathlib

- Data Engineering Tools: PySpark, Airflow, dbt, FastAPI (optional if you’ve used it), Prefect (if applicable)

- DevOps Tools: Docker, Kubernetes, Git, CI/CD tools (GitHub Actions, GitLab CI, etc.)



## Education
### Masters in Mathematics - 2021 - 2023
- Specializing in Statistics and Machine Learning
- Advanced knowledge of Linear Algebra (Matrices)
- Supervised learning 
- Unsupervised learning 
- Statistics - Probability Density Functions, Common distributions, Monte Carlo Simulations, Bootstrapping, Jackknife resampling, etc.
- Familiar with many parts of distributions such as compution of mean, variance, intervals, moment generating functions, maximum likelihood estimators, etc.
- Experience with estimating expected value, variance, etc. from probability density function utilizing Monte Carlo Simulation, Bootstrap, Jackknife, etc.

### Bachelors in Business and Economic Analytics  2017 - 2021
- Minored in Mathematics
- Econometrics
- Object Oriented Programming
- Data Driven Analytics
- Data Structures and Algorithms
- SQL 
